{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brenna/anaconda2/lib/python2.7/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import scipy.stats as st\n",
    "import random\n",
    "from datetime import datetime\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from patsy import dmatrix, dmatrices\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cur_dir = os.path.dirname('__file__')\n",
    "\n",
    "train = pd.read_csv(os.path.join(cur_dir, \"data\", \"train.csv\"))\n",
    "test = pd.read_csv(os.path.join(cur_dir, \"data\", \"test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_random_subset(df, n=5000):\n",
    "    sub = random.sample(xrange(len(df)), min(n, len(df)))\n",
    "    return df.iloc[sub]\n",
    "\n",
    "def preprocess(df):\n",
    "    res = df.copy()\n",
    "    res = res[res.X != res.X.max()]\n",
    "    datetimes = res.Dates.apply(get_datetime)\n",
    "    res['Hour'] = datetimes.apply(lambda dt: dt.hour)\n",
    "    res['Month'] = datetimes.apply(lambda dt: dt.month)\n",
    "    res['Hour_Minutes'] = datetimes.apply(lambda dt: dt.hour + dt.minute / 60.0)\n",
    "    res['Minutes_Since_03'] = datetimes.apply(lambda dt: (dt-datetime(2003, 1, 1)).total_seconds() / 60)\n",
    "    res['Minutes_Since_New_Year'] = datetimes.apply(lambda dt: (dt-datetime(dt.year, 1, 1)).total_seconds() / 60)\n",
    "    res['DOW'] = train.DayOfWeek.apply(lambda x: dow.index(x))\n",
    "    res['Street_Corner'] = res['Address'].apply(lambda x: 1 if '/' in x else 0)\n",
    "    return res\n",
    "\n",
    "def get_datetime(s):\n",
    "    dt = datetime.strptime(s, \"%Y-%m-%d %H:%M:%S\")\n",
    "    return dt\n",
    "\n",
    "dow = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "def isNight(hour):\n",
    "    if hour in [0, 1, 2, 3, 4, 5, 6, 19, 20, 21, 22, 23]:\n",
    "        return \"Night\"\n",
    "    else:\n",
    "        return \"Day\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = preprocess(get_random_subset(train, 5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   X              Y           Hour          Month  \\\n",
      "count  877982.000000  877982.000000  877982.000000  877982.000000   \n",
      "mean     -122.422763      37.767035      13.412737       6.436416   \n",
      "std         0.025285       0.024165       6.549521       3.428998   \n",
      "min      -122.513642      37.707879       0.000000       1.000000   \n",
      "25%      -122.432952      37.752427       9.000000       3.000000   \n",
      "50%      -122.416420      37.775421      14.000000       6.000000   \n",
      "75%      -122.406959      37.784368      19.000000       9.000000   \n",
      "max      -122.364937      37.819975      23.000000      12.000000   \n",
      "\n",
      "        Hour_Minutes  Minutes_Since_03  Minutes_Since_New_Year            DOW  \\\n",
      "count  877982.000000     877982.000000           877982.000000  877982.000000   \n",
      "mean       13.748657    3263716.192895           259058.977781       2.992719   \n",
      "std         6.560013    1908460.344165           151054.164970       1.972028   \n",
      "min         0.016667       7201.000000                1.000000       0.000000   \n",
      "25%         9.500000    1593126.500000           129326.000000       1.000000   \n",
      "50%        14.750000    3251129.000000           257121.000000       3.000000   \n",
      "75%        19.000000    4967235.000000           392882.000000       5.000000   \n",
      "max        23.983333    6503033.000000           525599.000000       6.000000   \n",
      "\n",
      "       Street_Corner  \n",
      "count  877982.000000  \n",
      "mean        0.296989  \n",
      "std         0.456932  \n",
      "min         0.000000  \n",
      "25%         0.000000  \n",
      "50%         0.000000  \n",
      "75%         1.000000  \n",
      "max         1.000000  \n"
     ]
    }
   ],
   "source": [
    "print train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-2b7b414f4292>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0my_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCategory\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mx_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_validation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_validation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;31m# y_validation = y_validation[y_validation.isin(y_train.values)]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# mlb = MultiLabelBinarizer(classes=alg.classes_)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "training, validation = train_test_split(train_df, train_size=.60)\n",
    "\n",
    "formula_ml = 'X+Y+Hour'\n",
    "formula_ml = 'C(DayOfWeek) + C(PdDistrict) + Street_Corner + X+Y+Hour+Month'\n",
    "x_train = dmatrix(formula_ml, data=training, return_type='dataframe')\n",
    "# print x_train\n",
    "# y_train = training.Category\n",
    "\n",
    "x_validation = dmatrix(formula_ml, data=validation, return_type='dataframe')\n",
    "y_validation = validation.Category\n",
    "\n",
    "x_validation = x_validation[y_validation.isin(y_train.values)]\n",
    "# y_validation = y_validation[y_validation.isin(y_train.values)]\n",
    "# mlb = MultiLabelBinarizer(classes=alg.classes_)\n",
    "# print y_validation\n",
    "# y_validation = mlb.fit_transform(np.array([y_validation]).T)\n",
    "\n",
    "num_trees = [5, 10, 50, 250]\n",
    "min_leaves = [10, 50, 500, 2500, 10000, 50000]\n",
    "\n",
    "for trees in num_trees:\n",
    "    scores = []\n",
    "    for l in min_leaves:\n",
    "        alg = RandomForestClassifier(min_samples_leaf=l)\n",
    "        alg.fit(x_train, y_train)\n",
    "        # alg = BernoulliNB()\n",
    "        y_validation = validation.Category\n",
    "        y_validation = y_validation[y_validation.isin(y_train.values)]\n",
    "        mlb = MultiLabelBinarizer(classes=alg.classes_)\n",
    "        y_validation = mlb.fit_transform(np.array([y_validation]).T)\n",
    "\n",
    "        predictions = np.array(alg.predict_proba(x_validation))\n",
    "        scores.append(log_loss(y_validation, predictions))\n",
    "    #     print \"Min leaf \" + str(l) + \": \" + str(log_loss(y_validation, predictions))\n",
    "    plt.plot(min_leaves, scores, label=(str(trees) + \" trees\"))\n",
    "plt.legend()\n",
    "plt.gca().set_xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training, validation = train_test_split(train_df, train_size=.60)\n",
    "\n",
    "formula_ml = 'C(DayOfWeek) + C(PdDistrict) + Street_Corner + X+Y+Hour+Month'\n",
    "x_train = dmatrix(formula_ml, data=training, return_type='dataframe')\n",
    "# print x_train\n",
    "# y_train = training.Category\n",
    "\n",
    "x_validation = dmatrix(formula_ml, data=validation, return_type='dataframe')\n",
    "y_validation = validation.Category\n",
    "\n",
    "x_validation = x_validation[y_validation.isin(y_train.values)]\n",
    "# y_validation = y_validation[y_validation.isin(y_train.values)]\n",
    "# mlb = MultiLabelBinarizer(classes=alg.classes_)\n",
    "# print y_validation\n",
    "# y_validation = mlb.fit_transform(np.array([y_validation]).T)\n",
    "\n",
    "weights = np.linspace(0.7, 1, 10)\n",
    "scores = []\n",
    "\n",
    "for w in weights:\n",
    "    alg1 = RandomForestClassifier(min_samples_leaf=1000)\n",
    "    alg2 = BernoulliNB()\n",
    "    alg1.fit(x_train, y_train)\n",
    "    alg2.fit(x_train, y_train)\n",
    "    # alg = BernoulliNB()\n",
    "    y_validation = validation.Category\n",
    "    y_validation = y_validation[y_validation.isin(y_train.values)]\n",
    "    mlb = MultiLabelBinarizer(classes=alg1.classes_)\n",
    "    y_validation = mlb.fit_transform(np.array([y_validation]).T)\n",
    "\n",
    "    predictions1 = np.array(alg1.predict_proba(x_validation))\n",
    "    predictions2 = np.array(alg2.predict_proba(x_validation))\n",
    "    predictions = (w * predictions1 + (1-w) * predictions2)\n",
    "    score = log_loss(y_validation, predictions)\n",
    "    scores.append(score)\n",
    "    #     print \"Min leaf \" + str(l) + \": \" + str(log_loss(y_validation, predictions))\n",
    "plt.plot(weights, scores)\n",
    "plt.xlabel(\"Percentage forest\")\n",
    "plt.ylabel(\"score\")\n",
    "# plt.gca().set_xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "formula_ml = 'C(DayOfWeek) + C(PdDistrict) + Street_Corner + X+Y+Hour+Month'\n",
    "\n",
    "x_vals = dmatrix(formula_ml, data=train_df, return_type='dataframe')\n",
    "y_vals = train_df.Category\n",
    "\n",
    "min_leaves = [10, 50, 500, 2500, 10000, 50000]\n",
    "\n",
    "parameters = {'min_samples_leaf':min_leaves}\n",
    "\n",
    "clf = GridSearchCV(RandomForestClassifier(), parameters, scoring='log_loss')\n",
    "\n",
    "clf.fit(x_vals, y_vals)\n",
    "\n",
    "print clf.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# k-Nearest Neighbor\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# load iris the datasets\n",
    "dataset = train.load_iris()\n",
    "# fit a k-nearest neighbor model to the data\n",
    "alg = KNeighborsClassifier()\n",
    "alg.fit(dataset.data, dataset.target)\n",
    "print(alg)\n",
    "# make predictions\n",
    "expected = dataset.target\n",
    "predicted = model.predict(dataset.data)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))\n",
    "\n",
    "# k-Nearest Neighbor\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# load iris the datasets\n",
    "dataset = datasets.load_iris()\n",
    "# fit a k-nearest neighbor model to the data\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(dataset.data, dataset.target)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = dataset.target\n",
    "predicted = model.predict(dataset.data)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-d9bd0e7e1e40>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-9-d9bd0e7e1e40>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    y = [:, train.Y]\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "X = train.X\n",
    "y = [train.Y]\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "neigh = KNeighborsRegressor(n_neighbors=2)\n",
    "neigh.fit(X, y) \n",
    "print(neigh.predict([[1.5]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training, validation = train_test_split(train_df, train_size=.60)\n",
    "\n",
    "formula_ml = 'C(DayOfWeek) + C(PdDistrict) + Street_Corner + X+Y+Hour+Month'\n",
    "x_train = dmatrix(formula_ml, data=training, return_type='dataframe')\n",
    "# print x_train\n",
    "# y_train = training.Category\n",
    "\n",
    "x_validation = dmatrix(formula_ml, data=validation, return_type='dataframe')\n",
    "y_validation = validation.Category\n",
    "\n",
    "x_validation = x_validation[y_validation.isin(y_train.values)]\n",
    "# y_validation = y_validation[y_validation.isin(y_train.values)]\n",
    "# mlb = MultiLabelBinarizer(classes=alg.classes_)\n",
    "# print y_validation\n",
    "# y_validation = mlb.fit_transform(np.array([y_validation]).T)\n",
    "\n",
    "weights = np.linspace(0.7, 1, 10)\n",
    "scores = []\n",
    "\n",
    "for w in weights:\n",
    "    alg1 = MultinomialNB()\n",
    "    alg.fit(x_train, y_train)\n",
    "    # alg = BernoulliNB()\n",
    "    y_validation = validation.Category\n",
    "    y_validation = y_validation[y_validation.isin(y_train.values)]\n",
    "    mlb = MultiLabelBinarizer(classes=alg1.classes_)\n",
    "    y_validation = mlb.fit_transform(np.array([y_validation]).T)\n",
    "\n",
    "    predictions1 = np.array(alg1.predict_proba(x_validation))\n",
    "    predictions2 = np.array(alg2.predict_proba(x_validation))\n",
    "    predictions = (w * predictions1 + (1-w) * predictions2)\n",
    "    score = log_loss(y_validation, predictions)\n",
    "    scores.append(score)\n",
    "    #     print \"Min leaf \" + str(l) + \": \" + str(log_loss(y_validation, predictions))\n",
    "plt.plot(weights, scores)\n",
    "plt.xlabel(\"Percentage forest\")\n",
    "plt.ylabel(\"score\")\n",
    "# plt.gca().set_xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name MLPClassifier",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-a18063644783>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mx_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_validation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_validation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneural_network\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name MLPClassifier"
     ]
    }
   ],
   "source": [
    "training, validation = train_test_split(train_df, train_size=.60)\n",
    "x_train = dmatrix(formula_ml, data=training, return_type='dataframe')\n",
    "y_train = training.Category\n",
    "\n",
    "x_validation = dmatrix(formula_ml, data=validation, return_type='dataframe')\n",
    "y_validation = validation.Category\n",
    "\n",
    "x_validation = x_validation[y_validation.isin(y_train.values)]\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "X = x_train\n",
    "y = y_train\n",
    "clf = MLPClassifier(algorithm='l-bfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "clf.fit(X, y) \n",
    "MLPClassifier(activation='relu', algorithm='l-bfgs', alpha=1e-05,\n",
    "       batch_size=200, beta_1=0.9, beta_2=0.999, early_stopping=False,\n",
    "       epsilon=1e-08, hidden_layer_sizes=(5, 2), learning_rate='constant',\n",
    "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
    "       tol=0.0001, validation_fraction=0.1, verbose=False,\n",
    "       warm_start=False)\n",
    "\n",
    "y_validation = validation.Category\n",
    "y_validation = y_validation[y_validation.isin(y_train.values)]\n",
    "mlb = MultiLabelBinarizer(classes=alg1.classes_)\n",
    "y_validation = mlb.fit_transform(np.array([y_validation]).T)\n",
    "\n",
    "predictions1 = np.array(alg1.predict_proba(x_validation))\n",
    "predictions2 = np.array(alg2.predict_proba(x_validation))\n",
    "predictions = (w * predictions1 + (1-w) * predictions2)\n",
    "score = log_loss(y_validation, predictions)\n",
    "scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2999, 21)\n",
      "(2999,)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Expecting same number of input and output samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-d5ce844708e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_vals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0my_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCategory\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/brenna/anaconda2/lib/python2.7/site-packages/sknn/mlp.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, w)\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalid_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalid_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRegressor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/brenna/anaconda2/lib/python2.7/site-packages/sknn/mlp.pyc\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, w)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m             \u001b[1;34m\"Expecting same number of input and output samples.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m         \u001b[0mdata_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Expecting same number of input and output samples."
     ]
    }
   ],
   "source": [
    "from numpy import newaxis\n",
    "from sknn.mlp import Regressor, Layer\n",
    "\n",
    "training, validation = train_test_split(train_df, train_size=.60)\n",
    "x_train = dmatrix(formula_ml, data=training)\n",
    "y_train = training.Category\n",
    "\n",
    "#data_array = x_train.values\n",
    "#for train_index, test_index in sss:\n",
    "#    xtrain, xtest = data_array[train_index], data_array[test_index]\n",
    "#    ytrain, ytest = target[train_index], target[test_index]\n",
    "\n",
    "f = 'Category'\n",
    "y_train_vals = dmatrix(f, data = train_df)[newaxis, :]\n",
    "#x_vals = dmatrix(formula_ml, data=train_df, return_type='dataframe')\n",
    "#y_vals = train_df.Category\n",
    "\n",
    "\n",
    "nn = Regressor(\n",
    "    layers=[\n",
    "        Layer(\"Rectifier\", units=100),\n",
    "        Layer(\"Linear\")],\n",
    "    learning_rate=0.02,\n",
    "    n_iter=10)\n",
    "print x_train.shape\n",
    "print y_train.shape\n",
    "nn.fit(x_train[0:4000], y_train_vals[0:4000])\n",
    "\n",
    "y_validation = validation.Category\n",
    "y_validation = y_validation[y_validation.isin(y_train.values)]\n",
    "mlb = MultiLabelBinarizer(classes=nn.classes_)\n",
    "y_validation = mlb.fit_transform(np.array([y_validation]).T)\n",
    "predictions = np.array(alg.predict_proba(x_validation))\n",
    "score = log_loss(y_validation, predictions)\n",
    "scores.append(score)\n",
    "\n",
    "print scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
