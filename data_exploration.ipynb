{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import scipy.stats as st\n",
    "import random\n",
    "# from datetime.datetime import strptime\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cur_dir = os.path.dirname('__file__')\n",
    "\n",
    "train = pd.read_csv(os.path.join(cur_dir, \"data\", \"train.csv\"))\n",
    "test = pd.read_csv(os.path.join(cur_dir, \"data\", \"test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    \n",
    "    res = df.copy()\n",
    "    res.drop(df.index[660485], inplace=True)\n",
    "    datetimes = res.Dates.apply(get_datetime)\n",
    "    res['Hour'] = datetimes.apply(lambda dt: dt.hour)\n",
    "    res['Month'] = datetimes.apply(lambda dt: dt.month)\n",
    "    res['Hour_Minutes'] = datetimes.apply(lambda dt: dt.hour + dt.minute / 60.0)\n",
    "    res['Minutes_Since_03'] = datetimes.apply(lambda dt: (dt-datetime(2003, 1, 1)).total_seconds() / 60)\n",
    "    res['Minutes_Since_New_Year'] = datetimes.apply(lambda dt: (dt-datetime(dt.year, 1, 1)).total_seconds() / 60)\n",
    "    return res\n",
    "\n",
    "def hour_min(s):\n",
    "    dt = get_datetime(s)\n",
    "    return dt.hour + dt.minute / 60.0\n",
    "\n",
    "def get_datetime(s):\n",
    "    dt = datetime.strptime(s, \"%Y-%m-%d %H:%M:%S\")\n",
    "    return dt\n",
    "\n",
    "def get_random_subset(df, n):\n",
    "    sub = random.sample(xrange(len(df)), n)\n",
    "    return df.iloc[sub]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = preprocess(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_common_cats = train.Category[train.Category != \"OTHER OFFENSES\"].value_counts().index[0:5]\n",
    "most_common_districts = train.PdDistrict.value_counts().index[0:5]\n",
    "\n",
    "\n",
    "f, axtuple = plt.subplots(1, len(most_common_cats), sharey=True)\n",
    "\n",
    "for i in range(len(most_common_districts)):\n",
    "    \n",
    "    subset = train[(train.PdDistrict == most_common_districts[i]) & train.Category.isin(most_common_cats)]\n",
    "    \n",
    "    ax = sns.countplot(x=\"Category\", data=subset.sort_values(\"Category\"), ax=axtuple[i])\n",
    "    ax.set_title(most_common_districts[i])\n",
    "    plt.sca(ax)\n",
    "    plt.xticks(rotation=90)\n",
    "    \n",
    "plt.gcf().set_size_inches(16, 6, forward=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_common_cats = train.Category[train.Category != \"OTHER OFFENSES\"].value_counts().index[0:5]\n",
    "most_common_districts = train.PdDistrict.value_counts().index[0:5]\n",
    "\n",
    "\n",
    "f, axtuple = plt.subplots(1, len(most_common_cats), sharey=True)\n",
    "\n",
    "\n",
    "for i in range(len(most_common_districts)):\n",
    "    \n",
    "    subset = train[train.PdDistrict == most_common_districts[i]]\n",
    "    proportions = (subset.Category.value_counts().astype(float) / len(subset)).loc[most_common_cats]\n",
    "    proportions = proportions.sort_index()\n",
    "    \n",
    "    \n",
    "    \n",
    "    ax = sns.barplot(x=proportions.index, y=proportions, ax=axtuple[i])\n",
    "    ax.set_title(most_common_districts[i])\n",
    "    ax.set_ylabel(\"\")\n",
    "    plt.sca(ax)\n",
    "    plt.xticks(rotation=90)\n",
    "    \n",
    "axtuple[0].set_ylabel(\"Frequency\")\n",
    "plt.gcf().set_size_inches(16, 6, forward=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_subset = get_random_subset(train, 5000)\n",
    "\n",
    "cats = [['LARCENY/THEFT', 'NON-CRIMINAL'], ['ASSAULT', 'DRUG/NARCOTIC']]\n",
    "\n",
    "f, axtuple = plt.subplots(2, 2, sharey=True, sharex=True)\n",
    "\n",
    "rows, cols = axtuple.shape\n",
    "\n",
    "for j in range(rows):\n",
    "    \n",
    "    for i in range(cols):\n",
    "\n",
    "        subset = train_subset[train_subset.Category == cats[j][i]]\n",
    "\n",
    "        x = subset.X\n",
    "        y = subset.Y\n",
    "\n",
    "        # plt.scatter(x, y)\n",
    "\n",
    "        xmin, xmax = x.min(), x.max()\n",
    "        ymin, ymax = y.min(), y.max()\n",
    "\n",
    "        # # Peform the kernel density estimate\n",
    "        xx, yy = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]\n",
    "        positions = np.vstack([xx.ravel(), yy.ravel()])\n",
    "        values = np.vstack([x, y])\n",
    "        kernel = st.gaussian_kde(values)\n",
    "        f = np.reshape(kernel(positions).T, xx.shape)\n",
    "\n",
    "        ax = axtuple[j, i]\n",
    "        ax.set_xlim(xmin, xmax)\n",
    "        ax.set_ylim(ymin, ymax)\n",
    "        ax.set_title(cats[j][i])\n",
    "        cfset = ax.contourf(xx, yy, f, cmap='Blues')\n",
    "        cset = ax.contour(xx, yy, f, colors='k')\n",
    "        ax.clabel(cset, inline=1, fontsize=10)\n",
    "    \n",
    "plt.gcf().set_size_inches(16, 6, forward=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(train_subset.X, train_subset.Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categories = train.Category.value_counts().index[0:6]\n",
    "bins = np.arange(1, 24, 1)\n",
    "for c in categories:\n",
    "    subset = train[train.Category == c]\n",
    "    indices = np.digitize(subset.Hour_Minutes, bins)\n",
    "    groups = subset.groupby(indices)\n",
    "    times = [g.Hour_Minutes.mean() for i, g in groups]\n",
    "    crimes = [len(g) for i, g in groups]\n",
    "    plt.plot(times, crimes, label=c)\n",
    "plt.legend()\n",
    "plt.gcf().set_size_inches(16, 6, forward=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
