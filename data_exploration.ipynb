{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import scipy.stats as st\n",
    "import random\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cur_dir = os.path.dirname('__file__')\n",
    "\n",
    "train = pd.read_csv(os.path.join(cur_dir, \"data\", \"train.csv\"))\n",
    "test = pd.read_csv(os.path.join(cur_dir, \"data\", \"test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_random_subset(df, n):\n",
    "    sub = random.sample(xrange(len(df)), n)\n",
    "    return df.iloc[sub]\n",
    "\n",
    "def preprocess(df):\n",
    "    res = df.copy()\n",
    "    res = res[res.X != res.X.max()]\n",
    "    res.drop(res.X.idxmax(), inplace=True)\n",
    "    datetimes = res.Dates.apply(get_datetime)\n",
    "    res['Hour'] = datetimes.apply(lambda dt: dt.hour)\n",
    "    res['Month'] = datetimes.apply(lambda dt: dt.month)\n",
    "    res['Hour_Minutes'] = datetimes.apply(lambda dt: dt.hour + dt.minute / 60.0)\n",
    "    res['Minutes_Since_03'] = datetimes.apply(lambda dt: (dt-datetime(2003, 1, 1)).total_seconds() / 60)\n",
    "    res['Minutes_Since_New_Year'] = datetimes.apply(lambda dt: (dt-datetime(dt.year, 1, 1)).total_seconds() / 60)\n",
    "    res['DOW'] = train.DayOfWeek.apply(lambda x: dow.index(x))\n",
    "    return res\n",
    "\n",
    "def get_datetime(s):\n",
    "    dt = datetime.strptime(s, \"%Y-%m-%d %H:%M:%S\")\n",
    "    return dt\n",
    "\n",
    "def get_random_subset(df, n=5000):\n",
    "    sub = random.sample(xrange(len(df)), n)\n",
    "    return df.iloc[sub]\n",
    "\n",
    "dow = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = preprocess(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_common_cats = train.Category[train.Category != \"OTHER OFFENSES\"].value_counts().index[0:5]\n",
    "most_common_districts = train.PdDistrict.value_counts().index[0:5]\n",
    "\n",
    "\n",
    "f, axtuple = plt.subplots(1, len(most_common_cats), sharey=True)\n",
    "\n",
    "for i in range(len(most_common_districts)):\n",
    "    \n",
    "    subset = train[(train.PdDistrict == most_common_districts[i]) & train.Category.isin(most_common_cats)]\n",
    "    \n",
    "    ax = sns.countplot(x=\"Category\", data=subset.sort_values(\"Category\"), ax=axtuple[i])\n",
    "    ax.set_title(most_common_districts[i])\n",
    "    plt.sca(ax)\n",
    "    plt.xticks(rotation=90)\n",
    "    \n",
    "plt.gcf().set_size_inches(16, 6, forward=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_common_cats = train.Category[train.Category != \"OTHER OFFENSES\"].value_counts().index[0:5]\n",
    "most_common_districts = train.PdDistrict.value_counts().index[0:5]\n",
    "\n",
    "\n",
    "f, axtuple = plt.subplots(1, len(most_common_cats), sharey=True)\n",
    "\n",
    "\n",
    "for i in range(len(most_common_districts)):\n",
    "    \n",
    "    subset = train[train.PdDistrict == most_common_districts[i]]\n",
    "    proportions = (subset.Category.value_counts().astype(float) / len(subset)).loc[most_common_cats]\n",
    "    proportions = proportions.sort_index()\n",
    "    \n",
    "    \n",
    "    \n",
    "    ax = sns.barplot(x=proportions.index, y=proportions, ax=axtuple[i])\n",
    "    ax.set_title(most_common_districts[i])\n",
    "    ax.set_ylabel(\"\")\n",
    "    plt.sca(ax)\n",
    "    plt.xticks(rotation=90)\n",
    "    \n",
    "axtuple[0].set_ylabel(\"Frequency\")\n",
    "plt.gcf().set_size_inches(16, 6, forward=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cats = [['LARCENY/THEFT', 'NON-CRIMINAL'], ['ASSAULT', 'DRUG/NARCOTIC']]\n",
    "\n",
    "train_subset = train[train.Category.isin(sum(cats, []))]\n",
    "\n",
    "train_subset = get_random_subset(train_subset)\n",
    "\n",
    "xmin, xmax = train.X.min(), train.X.max()\n",
    "ymin, ymax = train.Y.min(), train.Y.max()\n",
    "\n",
    "f, axtuple = plt.subplots(2, 2, sharey=True, sharex=True)\n",
    "\n",
    "rows, cols = axtuple.shape\n",
    "\n",
    "for j in range(rows):\n",
    "    \n",
    "    for i in range(cols):\n",
    "\n",
    "        subset = train_subset[train_subset.Category == cats[j][i]]\n",
    "\n",
    "        x = subset.X\n",
    "        y = subset.Y\n",
    "\n",
    "        # # Peform the kernel density estimate\n",
    "        xx, yy = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]\n",
    "        positions = np.vstack([xx.ravel(), yy.ravel()])\n",
    "        values = np.vstack([x, y])\n",
    "        kernel = st.gaussian_kde(values)\n",
    "        f = np.reshape(kernel(positions).T, xx.shape)\n",
    "\n",
    "    #     fig = plt.figure()\n",
    "        ax = axtuple[j, i]\n",
    "        ax.set_xlim(xmin, xmax)\n",
    "        ax.set_ylim(ymin, ymax)\n",
    "        ax.set_title(cats[j][i])\n",
    "        cfset = ax.contourf(xx, yy, f, cmap='Blues')\n",
    "#         cset = ax.contour(xx, yy, f, colors='k')\n",
    "#         ax.clabel(cset, inline=1, fontsize=10)\n",
    "    \n",
    "\n",
    "plt.gcf().set_size_inches(16, 6, forward=True)\n",
    "    \n",
    "# axtuple[0].set_ylabel(\"Frequency\")\n",
    "# plt.gcf().set_size_inches(16, 6, forward=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_common_cats = train.Category[train.Category != \"OTHER OFFENSES\"].value_counts().index[0:8]\n",
    "day_counts = train.DayOfWeek.value_counts().index[0:7]\n",
    "\n",
    "def isWeekend(day):\n",
    "    if day in [\"Saturday\", \"Sunday\"]:\n",
    "        return \"Weekend\"\n",
    "    else:\n",
    "        return \"Weekday\"\n",
    "\n",
    "\n",
    "train[\"Weekend\"] = train[\"DayOfWeek\"].apply(isWeekend)\n",
    "\n",
    "day_type_counts = train.Weekend.value_counts().index\n",
    "\n",
    "f, axtuple = plt.subplots(1, len(day_type_counts), sharey=True)\n",
    "\n",
    "\n",
    "for i, day in enumerate(day_type_counts):\n",
    "    \n",
    "    subset = train[train.Weekend == day]\n",
    "    proportions = (subset.Category.value_counts().astype(float) / len(subset)).loc[most_common_cats]\n",
    "    proportions = proportions.sort_index()\n",
    "    \n",
    "    ax = sns.barplot(x=proportions.index, y=proportions, ax=axtuple[i])\n",
    "    ax.set_title(day)\n",
    "    ax.set_ylabel(\"\")\n",
    "    plt.sca(ax)\n",
    "    plt.xticks(rotation=90)\n",
    "    \n",
    "axtuple[0].set_ylabel(\"Frequency\")\n",
    "plt.gcf().set_size_inches(16, 6, forward=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_Category(df):\n",
    "    cat_Count = df.groupby(\"Category\").count()\n",
    "    plt.figure()\n",
    "    cat_Count.sort_values(by=\"Dates\", ascending=1)[\"Dates\"].plot(kind=\"barh\")\n",
    "    plt.ticklabel_format(style='plain', axis='x', scilimits=(0,0))\n",
    "    plt.tight_layout()\n",
    "    plt.gcf().set_size_inches(16, 10, forward=True)\n",
    "    \n",
    "plot_Category(train_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categories = train.Category.value_counts().index[0:8]\n",
    "bins = np.arange(0,7, 1)\n",
    "for c in categories:\n",
    "    subset = train[train.Category == c]\n",
    "    indices = np.digitize(subset.DOW, bins)\n",
    "    groups = subset.groupby(indices)\n",
    "    days = [g.DOW.mean() for _, g in groups]\n",
    "    crimes = [len(g) for _, g in groups]\n",
    "    plt.plot(days, crimes, label=c)\n",
    "plt.legend(loc=2)\n",
    "plt.gcf().set_size_inches(16, 10, forward=True)\n",
    "plt.gca().set_xticklabels(dow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "categories = train.Category.value_counts().index[0:6]\n",
    "bins = np.arange(1, 24, 1)\n",
    "for c in categories:\n",
    "    subset = train[train.Category == c]\n",
    "    indices = np.digitize(subset.Hour_Minutes, bins)\n",
    "    groups = subset.groupby(indices)\n",
    "    times = [g.Hour_Minutes.mean() for i, g in groups]\n",
    "    crimes = [len(g) for i, g in groups]\n",
    "    plt.plot(times, crimes, label=c)\n",
    "plt.legend()\n",
    "plt.gcf().set_size_inches(16, 6, forward=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
