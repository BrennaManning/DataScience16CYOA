{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import scipy.stats as st\n",
    "import random\n",
    "from datetime import datetime\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from patsy import dmatrix, dmatrices\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur_dir = os.path.dirname('__file__')\n",
    "\n",
    "train = pd.read_csv(os.path.join(cur_dir, \"data\", \"train.csv\"))\n",
    "test = pd.read_csv(os.path.join(cur_dir, \"data\", \"test.csv\"))\n",
    "mapdata = np.loadtxt(os.path.join(cur_dir, \"data\", \"sf_map.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_random_subset(df, n=5000):\n",
    "    sub = random.sample(xrange(len(df)), min(n, len(df)))\n",
    "    return df.iloc[sub]\n",
    "\n",
    "def preprocess(df):\n",
    "    res = df.copy()\n",
    "    res = res[res.X != res.X.max()]\n",
    "    datetimes = res.Dates.apply(get_datetime)\n",
    "    res['Hour'] = datetimes.apply(lambda dt: dt.hour)\n",
    "    res['Month'] = datetimes.apply(lambda dt: dt.month)\n",
    "    res['Hour_Minutes'] = datetimes.apply(lambda dt: dt.hour + dt.minute / 60.0)\n",
    "    res['Minutes_Since_03'] = datetimes.apply(lambda dt: (dt-datetime(2003, 1, 1)).total_seconds() / 60)\n",
    "    res['Minutes_Since_New_Year'] = datetimes.apply(lambda dt: (dt-datetime(dt.year, 1, 1)).total_seconds() / 60)\n",
    "    res['DOW'] = train.DayOfWeek.apply(lambda x: dow.index(x))\n",
    "    res['Street_Corner'] = res['Address'].apply(lambda x: 1 if '/' in x else 0)\n",
    "    return res\n",
    "\n",
    "def get_datetime(s):\n",
    "    dt = datetime.strptime(s, \"%Y-%m-%d %H:%M:%S\")\n",
    "    return dt\n",
    "\n",
    "dow = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "def isNight(hour):\n",
    "    if hour in [0, 1, 2, 3, 4, 5, 6, 19, 20, 21, 22, 23]:\n",
    "        return \"Night\"\n",
    "    else:\n",
    "        return \"Day\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = preprocess(get_random_subset(train, len(train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training, validation = train_test_split(train_df, train_size=.60)\n",
    "\n",
    "formula_ml = 'X+Y+Hour'\n",
    "formula_ml = 'C(DayOfWeek) + C(PdDistrict) + Street_Corner + X+Y+Hour+Month'\n",
    "x_train = dmatrix(formula_ml, data=training, return_type='dataframe')\n",
    "# print x_train\n",
    "# y_train = training.Category\n",
    "\n",
    "x_validation = dmatrix(formula_ml, data=validation, return_type='dataframe')\n",
    "y_validation = validation.Category\n",
    "\n",
    "x_validation = x_validation[y_validation.isin(y_train.values)]\n",
    "# y_validation = y_validation[y_validation.isin(y_train.values)]\n",
    "# mlb = MultiLabelBinarizer(classes=alg.classes_)\n",
    "# print y_validation\n",
    "# y_validation = mlb.fit_transform(np.array([y_validation]).T)\n",
    "\n",
    "num_trees = [5, 10, 50, 250]\n",
    "min_leaves = [10, 50, 500, 2500, 10000, 50000]\n",
    "\n",
    "for trees in num_trees:\n",
    "    scores = []\n",
    "    for l in min_leaves:\n",
    "        alg = RandomForestClassifier(min_samples_leaf=l)\n",
    "        alg.fit(x_train, y_train)\n",
    "        # alg = BernoulliNB()\n",
    "        y_validation = validation.Category\n",
    "        y_validation = y_validation[y_validation.isin(y_train.values)]\n",
    "        mlb = MultiLabelBinarizer(classes=alg.classes_)\n",
    "        y_validation = mlb.fit_transform(np.array([y_validation]).T)\n",
    "\n",
    "        predictions = np.array(alg.predict_proba(x_validation))\n",
    "        scores.append(log_loss(y_validation, predictions))\n",
    "    #     print \"Min leaf \" + str(l) + \": \" + str(log_loss(y_validation, predictions))\n",
    "    plt.plot(min_leaves, scores, label=(str(trees) + \" trees\"))\n",
    "plt.legend()\n",
    "plt.gca().set_xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training, validation = train_test_split(train_df, train_size=.60)\n",
    "\n",
    "formula_ml = 'C(DayOfWeek) + C(PdDistrict) + Street_Corner + X+Y+Hour+Month'\n",
    "x_train = dmatrix(formula_ml, data=training, return_type='dataframe')\n",
    "# print x_train\n",
    "# y_train = training.Category\n",
    "\n",
    "x_validation = dmatrix(formula_ml, data=validation, return_type='dataframe')\n",
    "y_validation = validation.Category\n",
    "\n",
    "x_validation = x_validation[y_validation.isin(y_train.values)]\n",
    "# y_validation = y_validation[y_validation.isin(y_train.values)]\n",
    "# mlb = MultiLabelBinarizer(classes=alg.classes_)\n",
    "# print y_validation\n",
    "# y_validation = mlb.fit_transform(np.array([y_validation]).T)\n",
    "\n",
    "weights = np.linspace(0.7, 1, 10)\n",
    "scores = []\n",
    "\n",
    "for w in weights:\n",
    "    alg1 = RandomForestClassifier(min_samples_leaf=1000)\n",
    "    alg2 = BernoulliNB()\n",
    "    alg1.fit(x_train, y_train)\n",
    "    alg2.fit(x_train, y_train)\n",
    "    # alg = BernoulliNB()\n",
    "    y_validation = validation.Category\n",
    "    y_validation = y_validation[y_validation.isin(y_train.values)]\n",
    "    mlb = MultiLabelBinarizer(classes=alg1.classes_)\n",
    "    y_validation = mlb.fit_transform(np.array([y_validation]).T)\n",
    "\n",
    "    predictions1 = np.array(alg1.predict_proba(x_validation))\n",
    "    predictions2 = np.array(alg2.predict_proba(x_validation))\n",
    "    predictions = (w * predictions1 + (1-w) * predictions2)\n",
    "    score = log_loss(y_validation, predictions)\n",
    "    scores.append(score)\n",
    "    #     print \"Min leaf \" + str(l) + \": \" + str(log_loss(y_validation, predictions))\n",
    "plt.plot(weights, scores)\n",
    "plt.xlabel(\"Percentage forest\")\n",
    "plt.ylabel(\"score\")\n",
    "# plt.gca().set_xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mean: -2.95541, std: 0.03623, params: {'min_samples_leaf': 10}, mean: -2.48741, std: 0.00330, params: {'min_samples_leaf': 50}, mean: -2.46742, std: 0.00162, params: {'min_samples_leaf': 500}, mean: -2.50952, std: 0.00074, params: {'min_samples_leaf': 2500}, mean: -2.55335, std: 0.00147, params: {'min_samples_leaf': 10000}, mean: -2.62467, std: 0.00877, params: {'min_samples_leaf': 50000}]\n"
     ]
    }
   ],
   "source": [
    "formula_ml = 'C(DayOfWeek) + C(PdDistrict) + Street_Corner + X+Y+Hour+Month'\n",
    "\n",
    "x_vals = dmatrix(formula_ml, data=train_df, return_type='dataframe')\n",
    "y_vals = train_df.Category\n",
    "\n",
    "min_leaves = [10, 50, 500, 2500, 10000, 50000]\n",
    "\n",
    "parameters = {'min_samples_leaf':min_leaves}\n",
    "\n",
    "clf = GridSearchCV(RandomForestClassifier(), parameters, scoring='log_loss')\n",
    "\n",
    "clf.fit(x_vals, y_vals)\n",
    "\n",
    "print clf.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
